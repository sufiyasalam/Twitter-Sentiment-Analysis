from pyspark.sql import SparkSession
from pyspark.sql.functions import col, size, split, count

# âœ… Initialize Spark Session
spark = SparkSession.builder.appName("TwitterSentimentAnalysis").getOrCreate()

# âœ… Load CSV from local storage
file_path = "tweets_with_sentiment_cleaned.csv"  
df_spark = spark.read.csv(file_path, header=True, inferSchema=True)

# âœ… Display basic stats
print("\nğŸ” Dataset Summary:")
print(f"âœ… Total Tweets: {df_spark.count()}")

# âœ… Count sentiment distribution
print("\nğŸ“Š Sentiment Distribution:")
df_spark.groupBy("Sentiment").count().show()

# âœ… Word count analysis
df_spark = df_spark.withColumn("word_count", size(split(col("cleaned_text"), " ")))

print("\nğŸ” Average Word Count per Sentiment:")
df_spark.groupBy("Sentiment").agg({"word_count": "avg"}).show()
